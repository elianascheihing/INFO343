{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos  de tópicos dinámicos\n",
    "\n",
    "El objetivo de los modelos de tópicos dinámicos  es estudiar la deriva de los conceptos al interior de los tópicos.\n",
    "En <a href=\"https://mimno.infosci.cornell.edu/info6150/readings/dynamic_topic_models.pdf\"> Blei y Lafferty (2006)</a> se estudia el caso de las publicaciones científicas en la revista Science. Se consideraron 30,000 articulos, 250 en cada uno de los 120 años desde 1881 y 1999. Y se busca predecir los tópicos (la variación al interior de cada uno) en el año siguiente (2000).\n",
    "\n",
    "El tipo de resultados que obtienen es el siguiente:\n",
    "\n",
    "#### Tópico Física Atómica\n",
    "\n",
    "<img src=\"topicos1.png\" width=1000 height=500>\n",
    "<img src=\"topicos2.png\" width=1000 height=500>\n",
    "\n",
    "\n",
    "#### Tópico Neurociencia\n",
    "\n",
    "<img src=\"topicos3.png\" width=1000 height=500>\n",
    "<img src=\"topicos4.png\" width=1000 height=500>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para modelar la evolución temporal en la distribución de tópicos $k, k=1,\\cdots K$ se definen franjas (slices) de tiempo t y se reemplazan las distribuciones a priori Dirichlet  por **Logistic Normal**  en dos pasos:\n",
    "\n",
    "$$\\beta_{t,k} \\mid \\beta_{t-1,k} \\sim {\\cal{N}}(\\beta_{t-1,k}, \\sigma^2 I_{VxV}), \\qquad k=1,\\cdots K$$\n",
    "\n",
    "que se mapea en el simplex mediante la transformación logística:\n",
    "\n",
    "$$\\pi(\\beta_{t,k})_w = \\frac{exp(\\beta_{t,k,w})}{\\sum_{w \\in W} exp(\\beta_{t,k,w})}\\qquad k=1,\\cdots K$$\n",
    "\n",
    "\n",
    "donde $|W| =V$.\n",
    "\n",
    "\n",
    "De esta manera se propone el siguiente proceso generativo secuencial:\n",
    "\n",
    "1. Generar tópicos $\\beta_{t,k} \\mid \\beta_{t-1,k} \\sim {\\cal{N}}(\\beta_{t-1}, \\sigma^2 I_{VxV}$$\n",
    "\n",
    "y las respectivas funciones logísticas: \n",
    "\n",
    "$$\\phi_{t,k} = \\pi(\\beta_{t,k})_w = \\frac{exp(\\beta_{t,k,w})}{\\sum_{w \\in W} exp(\\beta_{t,k,w})}\\qquad k=1,\\cdots K$$\n",
    "\n",
    "2. Por cada documento:\n",
    "\n",
    "    (a) Generar $\\theta \\sim {\\cal{D}}irichlet(\\alpha)$\n",
    "    \n",
    "    (b) Por cada palabra en el documento $d$, generar\n",
    "        \n",
    "$$z \\sim Mult(\\theta) \\qquad \\text{y} \\qquad w_{t,d,n} \\sim Mult(\\phi(t,z))$$\n",
    "\n",
    "\n",
    "<img src=\"dtm.png\" width=500 height=500>         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la expresión de la distribución a posteriori \n",
    "$$p(\\phi_{1:T},\\theta_{1:D},z_{1:N}\\mid w_{1:N}) = \\frac{p(\\phi_{1:T},\\theta_{1:D},z_{1:N}, w_{1:N}) }{p(w_{1:N})}$$\n",
    "\n",
    "no es fácilmente calculable, incluso el numerador, debido a que la Normal Logistic no es natural conjugada de la distribución Multinomial.\n",
    "\n",
    "Es por ello que se recurre a métodos variacionales para aproximar la distribución a posteriori por una distribución cuyos parámetros se ajustan para que tenga mínima distancia de KL con la distribución a posteriori.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la formulación teórica, los parámetros que se requiere definir al realizar las aproximaciones son:\n",
    "\n",
    "- $\\sigma^2$ variance chain: es el parámetro que define la magnitud del ruido gaussiano que modela la variación temporal de los tópicos\n",
    "\n",
    "- $\\alpha =(\\alpha_1,\\cdots ,\\alpha_K)$ es el vector de parámetros de la distribución Dirichlet, que modela la variabilidad de tópicos en cada documento. Valores menores que uno y cercanos a 0 representan poca variabilidad entre tópicos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitaciones del Modelo de Tópicos Dinámicos\n",
    "\n",
    "- el número de tópicos no cambia en el tiempo\n",
    "- no interpreta automáticamente el significado de los tópicos (asiste la interpretación del humano, no elimina subjetividad)\n",
    "- modela tópicos según nuestros a priori (Número de tópicos, variance chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
